{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4559a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbaf2aaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/maali/code/3Maali/VAK_Project/raw_data/dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/maali/code/3Maali/VAK_Project/raw_data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9559ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524559f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# التأكد من أن التصنيفات في عمود Type هي: Auditory، Visual، Kinesthetic فقط.\n",
    "df_types = df['Type'].unique()\n",
    "# معرفة توزيع الأنماط (عدد الجمل لكل نمط).\n",
    "print(df_types)\n",
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b25b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # التأكد من أن جميع القيم في عمود Type صحيحة\n",
    "# valid_types = ['Auditory', 'Visual', 'Kinesthetic']\n",
    "# dataset = dataset[dataset['Type'].isin(valid_types)]\n",
    "\n",
    "# عرض عدد الصفوف بعد التنظيف\n",
    "print(f\"\\nعدد الصفوف بعد التنظيف: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8382d63",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea10e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تحميل الموارد اللازمة من NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إعداد قائمة الكلمات الشائعة وعلامات الترقيم\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# دالة لمعالجة النصوص\n",
    "def preprocess_text(text):\n",
    "    # تحويل إلى حروف صغيرة\n",
    "    text = text.lower()\n",
    "    # إزالة علامات الترقيم\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # تقطيع النص إلى كلمات\n",
    "    words = word_tokenize(text)\n",
    "    # إزالة الكلمات الشائعة وتوحيد الكلمات\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    # إعادة الكلمات كنص واحد\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Processed_Sentence'] = df['Sentence'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39859ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478fa6e",
   "metadata": {},
   "source": [
    "الخطوة 4: تحويل النصوص إلى تمثيلات رقمية\n",
    "لاستخدام النصوص في نماذج التعلم الآلي، نحتاج إلى تحويلها إلى تمثيلات رقمية. سنستخدم TF-IDF كمثال، لأنها طريقة شائعة وفعالة لتصنيف النصوص.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9331b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5de1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إنشاء متجه TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # تحديد عدد الميزات إلى 1000 كمثال\n",
    "X = vectorizer.fit_transform(df['Processed_Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997422fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تحويل الأنماط إلى أرقام (Label Encoding)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# عرض شكل المصفوفة الناتجة\n",
    "print(f\"شكل مصفوفة TF-IDF: {X.shape}\")\n",
    "print(f\"التصنيفات المشفرة: {y[:5]}\")\n",
    "print(f\"الأنماط الأصلية: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595f0e3",
   "metadata": {},
   "source": [
    "TfidfVectorizer: يحول النصوص إلى مصفوفة TF-IDF، حيث يتم وزن الكلمات بناءً على أهميتها.\n",
    "\n",
    "max_features=1000: يحدد عدد الكلمات الأكثر أهمية لتقليل الأبعاد.\n",
    "\n",
    "LabelEncoder: يحول التصنيفات (Auditory، Visual، Kinesthetic) إلى أرقام (مثل 0، 1، 2).\n",
    "\n",
    "X.shape: يعرض أبعاد المصفوفة الناتجة (عدد الجمل × عدد الميزات).\n",
    "\n",
    "label_encoder.classes_: يعرض الأنماط الأصلية المقابلة للأرقام.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71442f8e",
   "metadata": {},
   "source": [
    "الآن البيانات جاهزة لتدريب نموذج تصنيف (مثل Logistic Regression أو Random Forest).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859e4db",
   "metadata": {},
   "source": [
    "### استكشاف البيانات (Exploratory Data Analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbea265",
   "metadata": {},
   "source": [
    "الهدف هنا هو فهم البيانات بشكل أفضل من خلال:\n",
    "توزيع الأنماط: معرفة عدد الجمل لكل نمط (Auditory، Visual، Kinesthetic).\n",
    "\n",
    "الكلمات الشائعة: تحديد الكلمات الأكثر تكرارًا لكل نمط باستخدام Word Clouds.\n",
    "\n",
    "طول الجمل: تحليل طول الجمل لمعرفة ما إذا كان يختلف بين الأنماط.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd492c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e040988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035eebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. توزيع الأنماط\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='Type')\n",
    "plt.title('توزيع أنماط التعلم')\n",
    "plt.xlabel('النمط')\n",
    "plt.ylabel('عدد الجمل')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# دالة لإنشاء Word Cloud\n",
    "def plot_wordcloud(text, title):\n",
    "    # تحديد مسار الخط DejaVuSans.ttf\n",
    "    font_path = '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'\n",
    "\n",
    "    # إنشاء WordCloud مع تحديد font_path\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', font_path=font_path).generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# تجميع النصوص لكل نمط وإنشاء Word Clouds\n",
    "for learning_style in df['Type'].unique():\n",
    "    style_text = ' '.join(df[df['Type'] == learning_style]['Processed_Sentence'])\n",
    "    plot_wordcloud(style_text, f'Word Cloud لنمط {learning_style}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "font_path = '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'\n",
    "try:\n",
    "    font = ImageFont.truetype(font_path, size=12)\n",
    "    print(\"الخط صالح!\")\n",
    "except Exception as e:\n",
    "    print(f\"خطأ في الخط: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. تحليل طول الجمل\n",
    "df['Sentence_Length'] = df['Processed_Sentence'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df, x='Type', y='Sentence_Length')\n",
    "plt.title('توزيع طول الجمل حسب النمط')\n",
    "plt.xlabel('النمط')\n",
    "plt.ylabel('عدد الكلمات في الجملة')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdafb5",
   "metadata": {},
   "source": [
    "توزيع الأنماط: نستخدم countplot لرسم مخطط أعمدة يوضح عدد الجمل لكل نمط.\n",
    "\n",
    "Word Clouds: نستخدم مكتبة wordcloud لإنشاء سحابة كلمات تعرض الكلمات الأكثر تكرارًا لكل نمط.\n",
    "\n",
    "طول الجمل: نحسب عدد الكلمات في كل جملة (بعد المعالجة) ونرسم Box Plot لمقارنة طول الجمل بين الأنماط.\n",
    "\n",
    "_--___--_--\n",
    "تساعدنا هذه التحليلات على فهم السمات اللغوية لكل نمط.\n",
    "\n",
    "إذا كان هناك خلل في التوزيع (مثل نمط واحد يهيمن)، قد نحتاج إلى موازنة البيانات (مثل Oversampling أو Undersampling).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511be5ed",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAK_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
